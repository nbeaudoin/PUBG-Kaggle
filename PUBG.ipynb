{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In a PUBG game, up to 100 players start in each match (matchId). Players can be on teams (groupId) which get ranked at the end of the game (winPlacePerc) based on how many other teams are still alive when they are eliminated. In game, players can pick up different munitions, revive downed-but-not-out (knocked) teammates, drive vehicles, swim, run, shoot, and experience all of the consequences -- such as falling too far or running themselves over and eliminating themselves.\n",
    "\n",
    "You are provided with a large number of anonymized PUBG game stats, formatted so that each row contains one player's post-game stats. The data comes from matches of all types: solos, duos, squads, and custom; there is no guarantee of there being 100 players per match, nor at most 4 player per group.\n",
    "\n",
    "**You must create a model which predicts players' finishing placement based on their final stats, on a scale from 1 (first place) to 0 (last place).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Criteria\n",
    "\n",
    "Submissions are evaluated on Mean Absolute Error between your predicted winPlacePerc and the observed winPlacePerc.\n",
    "\n",
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "Submission File\n",
    "For each Id in the test set, you must predict their placement as a percentage (0 for last, 1 for first place) for the winPlacePerc variable. The file should contain a header and have the following format:\n",
    "\n",
    "  - Id,winPlacePerc\n",
    "  - 47734,0\n",
    "  - 47735,0.5\n",
    "  - 47736,0\n",
    "  - 47737,1\n",
    "  - etc.\n",
    "  \n",
    "See sample_submission.csv on the data page for a full sample submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "\n",
    "PATH = r'/Users/nicholasbeaudoin/Desktop/Kaggle/PUBG'\n",
    "\n",
    "# # Labels\n",
    "# df_train = pd.read_csv('../input/train_V2.csv')\n",
    "\n",
    "# # No labels\n",
    "# df_test = pd.read_csv('../input/test_V2.csv')\n",
    "\n",
    "# Labels\n",
    "df_train = pd.read_csv(f'{PATH}/data/train_V2.csv', low_memory=False)\n",
    "\n",
    "# No labels\n",
    "df_test = pd.read_csv(f'{PATH}/data/test_V2.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy out match type\n",
    "dummies_train = pd.get_dummies(df_train['matchType'])\n",
    "dummies_test = pd.get_dummies(df_test['matchType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dummies to DF\n",
    "df_train = pd.concat([df_train, dummies_train], axis=1)\n",
    "df_test = pd.concat([df_test, dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop IDs (3 of them)\n",
    "df_train.drop(['Id', 'groupId', 'matchId', 'matchType'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the one missing row with no observations for place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that one row was dropped\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pre-Process\n",
    "\n",
    "Feature selection, scaling, split-train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all variables except outcome\n",
    "feature_cols = df_train.columns[df_train.columns!='winPlacePerc']\n",
    "\n",
    "X = df_train[feature_cols]\n",
    "y = df_train.winPlacePerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Instantiate\n",
    "knn = KNeighborsRegressor(9)\n",
    "\n",
    "# Fit\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1,50):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    score = mean_absolute_error(y_pred, y_test)\n",
    "    scores.append([k, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(scores,columns=['k','score'])\n",
    "data.plot.line(x='k',y='score'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression\n",
    "\n",
    "One of the major advantages of decision trees is that they can pick up nonlinear interactions between variables in the data that linear regression canâ€™t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Instantiate the classifier\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "# Train model on training set\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Eval Metric\n",
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Train model on training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Eval Metric\n",
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "\n",
    " - Performs linear regression in a higher dimensional space\n",
    " - kernel = linear, polynomial, gaussian, rbf\n",
    " - We want rbf because we want non-linear\n",
    " - Need to apply feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import model\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Instantiate\n",
    "svr = SVR(kernel = 'rbf', gamma='scale')\n",
    "\n",
    "# Fit\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "### Evaluation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Predict\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search with Best Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf','poly'), 'C':[1, 5, 10, 15, 20], 'epsilon':[0.1]}\n",
    "svr = SVR()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply optimal parameters from GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "svr = SVR(kernel = 'rbf', gamma='scale', C=40, epsilon=0.1)\n",
    "\n",
    "# Fit\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "### Evaluation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Predict\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(df, features, algorithm):\n",
    "    x_oos = df[features]\n",
    "    algo = algorithm\n",
    "    algo.fit(X_train, y_train)\n",
    "    pred = algo.predict(x_oos)\n",
    "    \n",
    "    test_id = df[\"Id\"]\n",
    "    sub = pd.DataFrame({'Id': test_id, \"winPlacePerc\": pred} , columns=['Id', 'winPlacePerc'])\n",
    "    return sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(df_test, feature_cols, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a submission file\n",
    "'''\n",
    "import random\n",
    "\n",
    "# predict class probabilities for the actual testing data (not X_test)\n",
    "X_oos = df_test[feature_cols]\n",
    "\n",
    "svr = SVR(kernel = 'rbf', gamma='scale', C=40, epsilon=0.1)\n",
    "svr.fit(X_train,y_train)\n",
    "pred = svr.predict(X_oos)\n",
    "\n",
    "\n",
    "test_id = df_test[\"Id\"]\n",
    "sub = pd.DataFrame({'Id': test_id, \"winPlacePerc\": pred} , columns=['Id', 'winPlacePerc'])\n",
    "sub.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
